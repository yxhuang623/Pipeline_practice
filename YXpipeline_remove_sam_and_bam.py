import os
import codecs

os.system("mkdir ~/YXpipeline")
os.system("mkdir ~/YXpipeline/reference")
os.system("mkdir ~/YXpipeline/samples")
os.system("mkdir ~/YXpipeline/output_files")

# Download raw reads using sratoolkits
sranumber = open("SraAccList.txt")
sralist = list(sranumber)
# Obtain the total number of samples for further usage
totalsample_numbers = len(sralist)
print(totalsample_numbers)

for SRRnumber in sralist:
    SRRnumber = SRRnumber[0:10]
    #os.system("cd /home/yixiao/pipeline-practice/samples")
    command1 = "prefetch " + SRRnumber + " -O ~/YXpipeline/samples"
    os.system(command1)
    command3 = "fasterq-dump -S " + SRRnumber + " -O ~/YXpipeline/samples/" + SRRnumber
    os.system(command3)

# Create path to your original ref file and new ref path which will be generated by this pipeline
os.system("cd YXpipeline")
# Before running this pipeline, please create a new directionary named "reference_file"  
# in the same directionary where the "YXpipeline" were generated and put your ref file in "reference_file" directionary.
path = os.path.abspath("YXpipeline")
print(path)
path1 = os.path.abspath("reference_file")
print(path1)

fpath1 = path1 + "/"
rpath1 =[fpath1]
print(rpath1)
for file in os.listdir(path1):
    if file.endswith('.fasta'):
        print(file.__str__())
        rpath1.append(file.__str__())
        print(rpath1)
orirefpath = ''.join(rpath1)
print(orirefpath)

# Copy your input ref file to working place for this pipeline
os.system("cp -r " + orirefpath + " " + path + "/reference")

# Path to the reference
dpath = path + "/reference/"
rpath =[dpath]
print(rpath)
for file in os.listdir(path + "/reference"):
    if file.endswith('.fasta'):
        print(file.__str__())
        rpath.append(file.__str__())
        print(rpath)
referencepath = ''.join(rpath)
print(referencepath)

# Create index file for reference
os.system("bwa index " + referencepath)

# Creating the fasta index file for gatk haplotypecaller
os.system("samtools faidx " + referencepath)
# Creating the FASTA sequence dictionary file
os.system("gatk CreateSequenceDictionary -R " + referencepath)

# Create a sampleDirectories.txt which contain all the paths of samples
sampleDirectories = path + "/output_files/sampleDirectories.txt"
SD_file = open(sampleDirectories, 'w')
for sample_folder in os.listdir(path + "/samples"):
    print(sample_folder)
    fastqpath = []
    sample_folderpath = path + "/samples/" + sample_folder.__str__()
    print(sample_folderpath)
    #sample_folder_pathlist.append(sample_folderpath)

    SD_file.write(sample_folderpath + "\n")
SD_file.close()

# Alignment using BWA
for sample_folder in os.listdir(path + "/samples"):
    print(sample_folder)
    fastqpath = []
    sample_folderpath = path + "/samples/" + sample_folder.__str__()
    print(sample_folderpath)

    if (sample_folder.startswith(".")):
        continue
    else:
        for file in os.listdir(sample_folderpath):
            if (file.endswith(".fastq")):
                fastqpath.append(sample_folderpath + "/" + file.__str__())
        print(fastqpath)

        output_name = sample_folderpath + "/reads.sam"

        # Alignment
        command = "bwa mem " + referencepath + " " + \
                  fastqpath[0] + " " + fastqpath[1] + " > " + output_name
        os.system(command)

        # Convert sam to bam
        bam_name = sample_folderpath + "/YX.unsortedreads.bam"
        command = "samtools view -o " + bam_name + " " + sample_folderpath + "/reads.sam"
        os.system(command)

        # Sort bam
        sorted_name = sample_folderpath + "/YX.sortedreads.bam"
        os.system("samtools sort " + bam_name + " -o " + sorted_name)

        # Add @RG to BAM file
        RGsorted_name = sample_folderpath + "/RGsortedreads.bam"
        command = "gatk AddOrReplaceReadGroups I=" + sorted_name + " O=" + RGsorted_name + \
                  " RGID=4 RGLB=lib1 RGPL=ILLUMINA RGPU=unit1 RGSM=20"
        os.system(command)

        # Removing(marking) duplicates with GATK4
        dupsorted_name = sample_folderpath + "/dupsortedreads.bam"
        mdupsorted_name = sample_folderpath + "/dedup.metrics.txt"
        command = "gatk MarkDuplicates I=" + RGsorted_name + " O=" + dupsorted_name + \
                  " M=" + mdupsorted_name
        os.system(command)

        # Samtools index
        os.system("samtools index " + dupsorted_name)
        # Generate raw vcf files
        vcf_file_name = sample_folderpath + "/YX.raw.vcf"
        command = "gatk HaplotypeCaller -R " + referencepath + " -I " + dupsorted_name + \
                  " --minimum-mapping-quality 30 --sample-ploidy 1 -O " + vcf_file_name
        os.system(command)

        # Remove sam and bam files to save the storage
        os.system("rm " + output_name)
        os.system("rm " + bam_name)
        os.system("rm " + sorted_name)
        os.system("rm " + RGsorted_name)
        os.system("rm " + dupsorted_name)

        # Snp filter - gatk VariantFiltration - remove dense regions
        filter_vcf_output_name = sample_folderpath + "/YX.filter.vcf"

        command = 'gatk VariantFiltration -R  ' + referencepath + \
                  ' -cluster 3 -window 10 -V ' \
                  + vcf_file_name + ' -O ' + filter_vcf_output_name
        os.system(command)

        # Remove dense regions - Extract VCF with only "PASS"
        PASS_vcf_output_name = sample_folderpath + "/YX.PASS.vcf"
        reoutput_file = open(PASS_vcf_output_name, 'w')
        denfvcf_file = open(filter_vcf_output_name, 'r')
        line = denfvcf_file.readline()
        while (line):
            if (line[0] == "#"):
                reoutput_file.write(line)
            elif (line[0] != "#"):
                column = line.split("\t")
                if column[6] == "PASS":
                    reoutput_file.write(line)

            line = denfvcf_file.readline()
        reoutput_file.close()
        denfvcf_file.close()

        # Mark those failed-pass sites
        refilter_vcf_output_name = sample_folderpath + "/YX.refilter.vcf"
        command = 'gatk VariantFiltration -R ' + referencepath \
                  + ' -V ' + PASS_vcf_output_name + ' -O ' + refilter_vcf_output_name \
                  + ' --filter-name "MYfilter" --filter-expression "DP < 10 || AF < 0.75 || QD < 2"'

        os.system(command)

        # Replace the bases in those failed-pass sites with "N"
        remarked_file = sample_folderpath + "/YX.remarked.vcf"
        remarkedoutput_file = open(remarked_file, 'w')
        markedvcf_file = open(refilter_vcf_output_name, 'r')
        line = markedvcf_file.readline()
        while (line):
            if (line[0] == "#"):
                remarkedoutput_file.write(line)
            elif (line[0] != "#"):
                column = line.split("\t")
                if column[6] != "PASS":
                    line = line.replace(column[4], 'N')
                    remarkedoutput_file.write(line)
                else:
                    remarkedoutput_file.write(line)
            line = markedvcf_file.readline()

        remarkedoutput_file.close()
        markedvcf_file.close()

# Create a single merged snplist.txt file with all remarked-VCFs
command = "cfsan_snp_pipeline merge_sites -n YX.remarked.vcf -o " \
          "~/YXpipeline/output_files/snplist.txt " \
          "~/YXpipeline/output_files/sampleDirectories.txt " \
          "~/YXpipeline/output_files/filteredsampleDirectories.txt"
os.system(command)

# Keep the sites belong to the core genome in snplist.txt
filteredsnplist = "filteredsnplist.txt"
remarkedoutput_file = open(path + "/output_files/" + filteredsnplist, 'w')
snplistfile = open(path + "/output_files/snplist.txt", 'r')
listline = snplistfile.readline()

while(listline):
    token = listline.split("\t")
    if token[2] == totalsample_numbers.__str__():     #The number here is equal to the total number of samples
        remarkedoutput_file.write(listline)
    listline = snplistfile.readline()

remarkedoutput_file.close()
snplistfile.close()

# Create a [list] containing all the core-genome sites
fsnplistfile = codecs.open(path + "/output_files/filteredsnplist.txt", 'r')
snpsitsnumber = []
flistline = fsnplistfile.readline()
while flistline:
    token = flistline.split("\t")
    tokens = token[1]
    snpsitsnumber.append(tokens)
    flistline = fsnplistfile.readline()
fsnplistfile.close()

# Remove the non-core-genome sites in vcf file of each sample
for sample_folder in os.listdir(path + "/samples"):
    sample_folderpath = path + "/samples/" + sample_folder
    for files in os.listdir(sample_folderpath):
        if (files.endswith(".remarked.vcf")):
            remarked_vcffile = open(sample_folderpath + "/YX.remarked.vcf", 'r')
            coresnp = sample_folderpath + "/coresnp.vcf"
            coresnp_vcf = open(coresnp, "w")
            flistline = remarked_vcffile.readline()
            while (flistline):
                if (flistline[0] == "#"):
                    coresnp_vcf.write(flistline)
                elif (flistline[0] != "#"):
                    token = flistline.split("\t")
                    if token[1] in snpsitsnumber:
                        coresnp_vcf.write(flistline)
                flistline = remarked_vcffile.readline()
            coresnp_vcf.close()
            remarked_vcffile.close()

            # Generate a single pseudo-sequence for each sample- my own script
            coresnp_file = open(coresnp, "r")
            coresnpline = coresnp_file.readline()
            pseudo_seq_list = []
            while coresnpline:
                if (coresnpline[0] != "#"):
                    token = coresnpline.split("\t")
                    pseudo_seq_list.append(token[4][-1:])
                coresnpline = coresnp_file.readline()
            pseudo_seq_str = ''.join(pseudo_seq_list)

            # Write the title and pseudo_sequence into fasta file
            pse_output_name = sample_folderpath + "/pseudoseq.fasta"
            pse_output_file = open(pse_output_name, "w")
            pse_output_file.write(">" + sample_folderpath[32:] + "\n")
            pse_output_file.write(pseudo_seq_str+ "\n")
            pse_output_file.close()

# Create snp 'matrix' --combine files of consensus.fasta into single fasta file
pseq_list = []
for sample_folder in os.listdir(path + "/samples"):
    sample_folderpath = path + "/samples/" + sample_folder
    print(sample_folderpath)
    snpma_output_file = path + "/output_files/snpmatrix.fasta"
    opsnpma_output_file = open(snpma_output_file, "w")

    pseq_list.append(sample_folderpath + "/pseudoseq.fasta")
    print(pseq_list)

    for pseq_file_path in pseq_list:
        input_file = open(pseq_file_path, "r")
        line = input_file.readline()
        while (line):
            if line.startswith(">"):
                opsnpma_output_file.writelines(line)
            else:
                opsnpma_output_file.writelines(line)
            line = input_file.readline()

    opsnpma_output_file.close()

    # Create snp distance matrix by snp-dists
    command = "snp-dists ~/YXpipeline/output_files/snpmatrix.fasta > " \
              "~/YXpipeline/output_files/snpmatrix.tsv"
    os.system(command)
